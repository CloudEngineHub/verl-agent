from typing import List, Tuple, Dict, Union, Any
import torch
import numpy as np

def to_numpy(tensor):
    if isinstance(tensor, torch.Tensor):
        tensor = tensor.detach().cpu().numpy()
    elif isinstance(tensor, np.ndarray):
        tensor = tensor
    else:
        raise ValueError(f"Unsupported type: {type(tensor)})")
    return tensor

class EnvironmentManagerBase:
    def __init__(self, envs, projection_f):
        """
        Initialize the environment manager.
        
        Parameters:
        - envs: The environment instance, usually a vectorized environment containing multiple sub-environments.
        - projection_f: A function that maps text actions to environment actions.
        """
        self.envs = envs
        self.projection_f = projection_f

    def reset(self) -> Dict[str, Any]:
        """
        Reset all environments and return the initial observations.
        
        Returns:
        - next_observations (Dict):
          - 'text' (None or List[str]): The textual observation.
          - 'image' (np.ndarray or torch.Tensor): The image observation as either a NumPy array or a PyTorch tensor.
        """
        obs = self.envs.reset()
        return {
            'text': None,
            'image': obs
        }
    
    def step(self, text_actions: List[str]):
        """
        Execute text actions and return the next state, rewards, done flags, and additional information.
        
        Parameters:
        - text_actions (List[str]): A list of text actions to execute.
        
        Returns:
        - next_observations (Dict):
          - 'text' (None or List[str]): The textual observation.
          - 'image' (np.ndarray or torch.Tensor): The image observation as either a NumPy array or a PyTorch tensor.
        - rewards (np.ndarry or torch.Tensor): The rewards returned by the environment.
        - dones (np.ndarray or torch.Tensor): Done flags indicating which environments have completed.
        - infos (List[Dict]): Additional environment information.
        
        Exceptions:
        - NotImplementedError: If an observation key is not in ('text', 'image').
        """
        actions, valid = self.projection_f(text_actions)
        next_obs, rewards, dones, infos = self.envs.step(actions)

        next_observations = {
            'text': None, # TODO: Implement this if needed
            'image': next_obs
        }
        # add action_valid to infos
        for i, info in enumerate(infos):
            info['is_action_valid'] = to_numpy(valid[i])

        return next_observations, rewards, dones, infos

    def close(self) -> None:
        """
        Close the environment and release resources.
        """
        self.envs.close()

    def success_evaluator(self, *args, **kwargs):
        """
        Evaluate if the episodes are successful or not. 
        (Default) implementation is to check if the total rewards are greater than 0.
        
        Returns:
        - success (np.ndarray or torch.Tensor): 1 if the episode is successful, 0 otherwise.
        """
        episode_rewards = kwargs['episode_rewards']
        success = episode_rewards > 0
        return success


# Customizing the your own environment manager: 
class GymCardEnvironmentManager(EnvironmentManagerBase):
    def __init__(self, envs, projection_f, env_name):
        self.env_name = env_name
        super().__init__(envs, projection_f)
    
    def reset(self) -> Dict[str, Any]:
        observations = super().reset()
        if self.env_name == 'gym_cards/EZPoints-v0' or self.env_name == 'gym_cards/Points24-v0':
            observations['text'] = ["The current formula is empty. Now it's your turn to choose a number or operator as the beginning of the formula."] * len(observations)
        
        return observations

    def step(self, text_actions: List[str]):
        next_observations, rewards, dones, infos = super().step(text_actions)
        
        # add text observation to next_observations
        if self.env_name == 'gym_cards/EZPoints-v0' or self.env_name == 'gym_cards/Points24-v0':
            next_observations['text'] = self.build_text_observation(infos)

        return next_observations, rewards, dones, infos
    
    def success_evaluator(self, *args, **kwargs):
        return super().success_evaluator(*args, **kwargs)
    
    def build_text_observation(self, infos: Tuple[Dict]) -> List[str]:
        text_observations = []
        for info in infos:
            text_formula = ''.join(str(element) for element in info['Formula'])
            if text_formula == '' or text_formula == ' ':
                text_observation = "The current formula is empty. Now it's your turn to choose a number or operator as the beginning of the formula."
            else:
                text_observation = f"The current formula is \"{text_formula}\". Now it's your turn to add a number or operator to the end of \"{text_formula}\"."
            text_observations.append(text_observation)

        return text_observations

    
    

        